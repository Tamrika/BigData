{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Named Entity Recognition with Spark NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMg61CqKGpCbWih+zrZcqfO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tamrika/BigData/blob/main/Named_Entity_Recognition_with_Spark_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHUK6ZfGiz9f"
      },
      "source": [
        "# Named Entity Recognition with Spark NLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbEQG6Izi-Nw"
      },
      "source": [
        "## Installing Java 8(3.2.1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euFiaCr4IvBU",
        "outputId": "508d65bf-b7ea-4d41-a03a-2143f9bdeac4"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "!update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n",
        "!java -version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"1.8.0_282\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_282-8u282-b08-0ubuntu1~18.04-b08)\n",
            "OpenJDK 64-Bit Server VM (build 25.282-b08, mixed mode)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GsFnEiuqa2T"
      },
      "source": [
        "## Installing pyspark and nlp(version specific)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "PnDO2rWZI7WY",
        "outputId": "6a4c5a20-2605-4e05-e8c3-7135a6ee50a0"
      },
      "source": [
        "# Install pyspark\n",
        "! pip install --ignore-installed pyspark==2.4.4\n",
        "# Install Spark NLP\n",
        "! pip install --ignore-installed spark-nlp==2.6.3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing /root/.cache/pip/wheels/ab/09/4d/0d184230058e654eb1b04467dbc1292f00eaa186544604b471/pyspark-2.4.4-py2.py3-none-any.whl\n",
            "Collecting py4j==0.10.7\n",
            "  Using cached https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "py4j",
                  "pyspark"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting spark-nlp==2.6.3\n",
            "  Using cached https://files.pythonhosted.org/packages/84/84/3f15673db521fbc4e8e0ec3677a019ba1458b2cb70f0f7738c221511ef32/spark_nlp-2.6.3-py2.py3-none-any.whl\n",
            "Installing collected packages: spark-nlp\n",
            "Successfully installed spark-nlp-2.6.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "com",
                  "sparknlp"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUGOhW91q3cB"
      },
      "source": [
        "## Import the relevant packages(3.2.2) and retrieve Spark version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yb-U_fxEU6o",
        "outputId": "dd803b65-6abc-4b05-8792-f506cc7bf5e4"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml import Pipeline\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.common import *\n",
        "from sparknlp.base import *\n",
        "import sparknlp\n",
        "spark = sparknlp.start()\n",
        "print(\"Spark NLP version: \", sparknlp.version())\n",
        "print(\"Apache Spark version: \", spark.version)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spark NLP version:  2.6.3\n",
            "Apache Spark version:  2.4.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvKb122krN15"
      },
      "source": [
        "## Downloading the CoNLL dataset(3.2.3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtIpMbwDE-HX",
        "outputId": "cd7945b2-b20b-4e10-a586-079a075c0337"
      },
      "source": [
        "from pathlib import Path\n",
        "import urllib.request\n",
        "download_path = \"./eng.train\"\n",
        "if not Path(download_path).is_file():\n",
        " print(\"File Not found will download it!\")\n",
        " url = \"https://raw.githubusercontent.com/patverga/torch-ner-nlp-from-scratch/master/data/conll2003/eng.train\"\n",
        " urllib.request.urlretrieve(url, download_path)\n",
        "else:\n",
        " print(\"File already present.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File Not found will download it!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltsqQ-qjrZ3l"
      },
      "source": [
        "## Converting the CoNLL file to Spark data frame(3.2.4)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIQqpbO4GM6P",
        "outputId": "d5d4bffa-248c-49eb-aa87-5ffa88a395c2"
      },
      "source": [
        "from sparknlp.training import CoNLL\n",
        "training_data = CoNLL().readDataset(spark, './eng.train')\n",
        "training_data.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                text|            document|            sentence|               token|                 pos|               label|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|EU rejects German...|[[document, 0, 47...|[[document, 0, 47...|[[token, 0, 1, EU...|[[pos, 0, 1, NNP,...|[[named_entity, 0...|\n",
            "|     Peter Blackburn|[[document, 0, 14...|[[document, 0, 14...|[[token, 0, 4, Pe...|[[pos, 0, 4, NNP,...|[[named_entity, 0...|\n",
            "| BRUSSELS 1996-08-22|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 7, BR...|[[pos, 0, 7, NNP,...|[[named_entity, 0...|\n",
            "|The European Comm...|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 2, Th...|[[pos, 0, 2, DT, ...|[[named_entity, 0...|\n",
            "|Germany 's repres...|[[document, 0, 21...|[[document, 0, 21...|[[token, 0, 6, Ge...|[[pos, 0, 6, NNP,...|[[named_entity, 0...|\n",
            "|\" We do n't suppo...|[[document, 0, 16...|[[document, 0, 16...|[[token, 0, 0, \",...|[[pos, 0, 0, \", [...|[[named_entity, 0...|\n",
            "|He said further s...|[[document, 0, 13...|[[document, 0, 13...|[[token, 0, 1, He...|[[pos, 0, 1, PRP,...|[[named_entity, 0...|\n",
            "|He said a proposa...|[[document, 0, 22...|[[document, 0, 22...|[[token, 0, 1, He...|[[pos, 0, 1, PRP,...|[[named_entity, 0...|\n",
            "|Fischler proposed...|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 7, Fi...|[[pos, 0, 7, JJR,...|[[named_entity, 0...|\n",
            "|But Fischler agre...|[[document, 0, 21...|[[document, 0, 21...|[[token, 0, 2, Bu...|[[pos, 0, 2, CC, ...|[[named_entity, 0...|\n",
            "|Spanish Farm Mini...|[[document, 0, 16...|[[document, 0, 16...|[[token, 0, 6, Sp...|[[pos, 0, 6, NNP,...|[[named_entity, 0...|\n",
            "|                   .|[[document, 0, 0,...|[[document, 0, 0,...|[[token, 0, 0, .,...|[[pos, 0, 0, ., [...|[[named_entity, 0...|\n",
            "|Only France and B...|[[document, 0, 52...|[[document, 0, 52...|[[token, 0, 3, On...|[[pos, 0, 3, RB, ...|[[named_entity, 0...|\n",
            "|The EU 's scienti...|[[document, 0, 17...|[[document, 0, 17...|[[token, 0, 2, Th...|[[pos, 0, 2, DT, ...|[[named_entity, 0...|\n",
            "|Sheep have long b...|[[document, 0, 17...|[[document, 0, 17...|[[token, 0, 4, Sh...|[[pos, 0, 4, NNP,...|[[named_entity, 0...|\n",
            "|British farmers d...|[[document, 0, 21...|[[document, 0, 21...|[[token, 0, 6, Br...|[[pos, 0, 6, JJ, ...|[[named_entity, 0...|\n",
            "|\" What we have to...|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 0, \",...|[[pos, 0, 0, \", [...|[[named_entity, 0...|\n",
            "|Bonn has led effo...|[[document, 0, 21...|[[document, 0, 21...|[[token, 0, 3, Bo...|[[pos, 0, 3, NNP,...|[[named_entity, 0...|\n",
            "|Germany imported ...|[[document, 0, 84...|[[document, 0, 84...|[[token, 0, 6, Ge...|[[pos, 0, 6, NNP,...|[[named_entity, 0...|\n",
            "|It brought in 4,2...|[[document, 0, 82...|[[document, 0, 82...|[[token, 0, 1, It...|[[pos, 0, 1, PRP,...|[[named_entity, 0...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0B08AInrr-q"
      },
      "source": [
        "## Word embeddings through BERT,Spark NLP annotator(3.2.5)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pakw2EpH1Jb",
        "outputId": "266a97c2-24ad-4844-aed3-2c4d167071ee"
      },
      "source": [
        "bert = BertEmbeddings.pretrained('bert_base_cased', 'en') \\\n",
        ".setInputCols([\"sentence\",'token'])\\\n",
        ".setOutputCol(\"bert\")\\\n",
        ".setCaseSensitive(False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bert_base_cased download started this may take some time.\n",
            "Approximate size to download 389.1 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVRC-LousCt1"
      },
      "source": [
        "## Configuring Tagger and Import the NerDLApproach() annotator,responsible for training the NER model(3.2.6)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLZ-N8NcJ9h5"
      },
      "source": [
        "nerTagger = NerDLApproach()\\\n",
        ".setInputCols([\"sentence\", \"token\", \"bert\"])\\\n",
        ".setLabelColumn(\"label\")\\\n",
        ".setOutputCol(\"ner\")\\\n",
        ".setMaxEpochs(1)\\\n",
        ".setRandomSeed(0)\\\n",
        ".setVerbose(1)\\\n",
        ".setValidationSplit(0.2)\\\n",
        ".setEvaluationLogExtended(True)\\\n",
        ".setEnableOutputLogs(True)\\\n",
        ".setIncludeConfidence(True)\\\n",
        ".setTestDataset(\"test_withEmbeds.parquet\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmzyzbe5setZ"
      },
      "source": [
        "## Download testing data(3.2.7.1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBMVpMdcNDDW",
        "outputId": "f0df65fd-3f5e-4ffb-fbe4-927a337f6940"
      },
      "source": [
        "from pathlib import Path\n",
        "import urllib.request\n",
        "download_path = \"./eng.testa\"\n",
        "if not Path(download_path).is_file():\n",
        " print(\"File Not found will download it!\")\n",
        " url = \"https://raw.githubusercontent.com/patverga/torch-ner-nlp-from-scratch/master/data/conll2003/eng.testa\"\n",
        " urllib.request.urlretrieve(url, download_path)\n",
        "else:\n",
        " print(\"File already present.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File Not found will download it!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJSNr5f8sly-"
      },
      "source": [
        "## Transforming and saving test data(3.2.7.1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuObuGcNNgPO"
      },
      "source": [
        "test_data = CoNLL().readDataset(spark, './eng.testa')\n",
        "test_data = bert.transform(test_data)\n",
        "test_data.write.parquet(\"test_withEmbeds.parquet\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WtJblAFtfNW"
      },
      "source": [
        "## Append annotators bert and nerTagger in a pipeline and train the NER model with the training dataset(3.2.8)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBetIB77QG4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "outputId": "fb87a725-1d29-4a3a-baf7-2a29e2b9387f"
      },
      "source": [
        "%%time\n",
        "ner_pipeline = Pipeline(stages = [bert, nerTagger])\n",
        "ner_model = ner_pipeline.fit(training_data.limit(100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-2da813fafb81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ner_pipeline = Pipeline(stages = [bert, nerTagger])\\nner_model = ner_pipeline.fit(training_data.limit(100))'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/ml/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    107\u001b[0m                     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# must be an Estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m                     \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mindexOfLastEstimator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \"\"\"\n\u001b[1;32m    291\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1257\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRoyqD9H0ac0"
      },
      "source": [
        "## Get predictions using test dataset.(3.2.9)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcRwsjn-TVF9"
      },
      "source": [
        "predictions = ner_model.tranform(test_data)\n",
        "predictions.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCelf42gTuTp"
      },
      "source": [
        "predictions.select('token.result','label.result','ner.result').show(truncate=40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BhCBzzr0xIU"
      },
      "source": [
        "### By printing schema, we can see the schema of the ‘predictions’ DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ny4OYC5ITe7W"
      },
      "source": [
        "predictions.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "na_ksGn91aT9"
      },
      "source": [
        "### Formatting to make it look better"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPxoGRi7UL9B"
      },
      "source": [
        "import pyspark.sql.functions as F\n",
        "predictions.select(F.explode(F.arrays_zip('token.result','label.result','ner.result')).alias(\"cols\")) \\\n",
        ".select(F.expr(\"cols['0']\").alias(\"token\"),\n",
        "        F.expr(\"cols['1']\").alias(\"ground_truth\"),\n",
        "        F.expr(\"cols['2']\").alias(\"prediction\")).show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttmcFq23bcON"
      },
      "source": [
        "##Assignment 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSAclK1v-ZFP"
      },
      "source": [
        "### Import necessary packages other than previously imported packages. Make sure Java, pyspark and nlp are installed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipLX7dXs2gaI"
      },
      "source": [
        "### Annotated (NER) the text given using a PretrainedPipeline(recognize_entities_dl) in SparkNLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cr43O0mbygE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29aac4b8-f80a-4b1f-b9e9-dba4ee029479"
      },
      "source": [
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "from pyspark import SparkContext,since\n",
        "spark=sparknlp.start()\n",
        "pipeline=PretrainedPipeline(\"recognize_entities_dl\", lang=\"en\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "recognize_entities_dl download started this may take some time.\n",
            "Approx size to download 159 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7BGMTpU919Q"
      },
      "source": [
        "### Store the text to be analyzed in a variable named text "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7D7kIH4nfVpt"
      },
      "source": [
        "text=\"\"\"The University of Illinois Springfield (UIS) is a public university in Springfield, Illinois, United\n",
        "States. The university was established in 1969 as Sangamon State University by the Illinois\n",
        "General Assembly and became a part of the University of Illinois system on July 1, 1995. As a\n",
        "public liberal arts college, and the newest campus in the University of Illinois system, UIS is a\n",
        "member of the Council of Public Liberal Arts Colleges. President: Timothy L. Killeen.\n",
        "Chancellor: Karen M. Whitney. Location: Springfield, Illinois, United States.\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_pMvf_b-FJ2"
      },
      "source": [
        "### Annotate 'text' and save it in 'result'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRhh74Ckgu-2"
      },
      "source": [
        "result = pipeline.annotate(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_0eKMz2-Qap"
      },
      "source": [
        "### Retrieve and print the output from 'result'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qKEuo_lgM5_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e8d5f7a-2b31-4d86-cc85-8a44ff8493db"
      },
      "source": [
        "for data in list(zip(result['token'],result['ner'])):\n",
        "  print(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('The', 'O')\n",
            "('University', 'B-ORG')\n",
            "('of', 'I-ORG')\n",
            "('Illinois', 'I-ORG')\n",
            "('Springfield', 'I-ORG')\n",
            "('(', 'O')\n",
            "('UIS', 'B-ORG')\n",
            "(')', 'O')\n",
            "('is', 'O')\n",
            "('a', 'O')\n",
            "('public', 'O')\n",
            "('university', 'O')\n",
            "('in', 'O')\n",
            "('Springfield', 'B-LOC')\n",
            "(',', 'O')\n",
            "('Illinois', 'B-LOC')\n",
            "(',', 'O')\n",
            "('United', 'B-LOC')\n",
            "('States', 'I-LOC')\n",
            "('.', 'O')\n",
            "('The', 'O')\n",
            "('university', 'O')\n",
            "('was', 'O')\n",
            "('established', 'O')\n",
            "('in', 'O')\n",
            "('1969', 'O')\n",
            "('as', 'O')\n",
            "('Sangamon', 'B-ORG')\n",
            "('State', 'I-ORG')\n",
            "('University', 'I-ORG')\n",
            "('by', 'O')\n",
            "('the', 'O')\n",
            "('Illinois', 'B-ORG')\n",
            "('General', 'I-ORG')\n",
            "('Assembly', 'I-ORG')\n",
            "('and', 'O')\n",
            "('became', 'O')\n",
            "('a', 'O')\n",
            "('part', 'O')\n",
            "('of', 'O')\n",
            "('the', 'O')\n",
            "('University', 'B-ORG')\n",
            "('of', 'I-ORG')\n",
            "('Illinois', 'I-ORG')\n",
            "('system', 'O')\n",
            "('on', 'O')\n",
            "('July', 'O')\n",
            "('1', 'O')\n",
            "(',', 'O')\n",
            "('1995', 'O')\n",
            "('.', 'O')\n",
            "('As', 'O')\n",
            "('a', 'O')\n",
            "('public', 'O')\n",
            "('liberal', 'O')\n",
            "('arts', 'O')\n",
            "('college', 'O')\n",
            "(',', 'O')\n",
            "('and', 'O')\n",
            "('the', 'O')\n",
            "('newest', 'O')\n",
            "('campus', 'O')\n",
            "('in', 'O')\n",
            "('the', 'O')\n",
            "('University', 'B-ORG')\n",
            "('of', 'I-ORG')\n",
            "('Illinois', 'I-ORG')\n",
            "('system', 'O')\n",
            "(',', 'O')\n",
            "('UIS', 'B-ORG')\n",
            "('is', 'O')\n",
            "('a', 'O')\n",
            "('member', 'O')\n",
            "('of', 'O')\n",
            "('the', 'O')\n",
            "('Council', 'B-ORG')\n",
            "('of', 'I-ORG')\n",
            "('Public', 'I-ORG')\n",
            "('Liberal', 'I-ORG')\n",
            "('Arts', 'I-ORG')\n",
            "('Colleges', 'I-ORG')\n",
            "('.', 'O')\n",
            "('President', 'O')\n",
            "(':', 'O')\n",
            "('Timothy', 'B-PER')\n",
            "('L', 'I-PER')\n",
            "('.', 'O')\n",
            "('Killeen', 'B-PER')\n",
            "('.', 'O')\n",
            "('Chancellor', 'O')\n",
            "(':', 'O')\n",
            "('Karen', 'B-PER')\n",
            "('M', 'I-PER')\n",
            "('.', 'O')\n",
            "('Whitney', 'B-PER')\n",
            "('.', 'O')\n",
            "('Location', 'O')\n",
            "(':', 'O')\n",
            "('Springfield', 'B-LOC')\n",
            "(',', 'O')\n",
            "('Illinois', 'B-LOC')\n",
            "(',', 'O')\n",
            "('United', 'B-LOC')\n",
            "('States', 'I-LOC')\n",
            "('.', 'O')\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}